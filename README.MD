eco-pulse-lakehouse/
â”‚
â”œâ”€â”€ config/                 # Configuraciones (YAMLs, JSONs)
â”‚   â””â”€â”€ spark_config.conf   # Configs de Spark (memoria, cores)
â”‚
â”œâ”€â”€ data/                   # Datos locales (solo para pruebas, ignorado en git)
â”‚   â”œâ”€â”€ gold/
â”‚   â””â”€â”€ silver/
â”‚   â””â”€â”€ bronze/
â”‚
â”œâ”€â”€ docker/                 # Dockerfiles personalizados (si los necesitamos)
â”‚
â”œâ”€â”€ notebooks/              # Jupyter Notebooks para experimentaciÃ³n (EDA)
â”‚   â””â”€â”€ 01_explore_nasa_api.ipynb
â”‚
â”œâ”€â”€ src/                    # CÃ“DIGO FUENTE PRINCIPAL
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ingestion/          # Scripts del Producer (Python + Kafka)
â”‚   â”‚   â””â”€â”€ nasa_producer.py
â”‚   â”œâ”€â”€ processing/         # Scripts de Spark (Streaming + Batch)
â”‚   â”‚   â””â”€â”€ fire_risk_processor.py
â”‚   â”œâ”€â”€ utils/              # Funciones auxiliares (loggers, connectores)
â”‚   â”‚   â””â”€â”€ spark_utils.py
â”‚   â””â”€â”€ visualization/      # Streamlit App
â”‚       â””â”€â”€ app.py
â”‚
â”œâ”€â”€ .env                    # VARIABLES DE ENTORNO (API KEYS - Â¡Nunca al git!)
â”œâ”€â”€ .gitignore              # Archivos a ignorar
â”œâ”€â”€ docker-compose.yml      # La infraestructura completa
â”œâ”€â”€ README.md               # DocumentaciÃ³n del proyecto
â””â”€â”€ requirements.txt        # Dependencias de Python


ğŸŒ PROYECTO: Eco-Pulse Lakehouse

Tagline: Sistema de monitorizaciÃ³n de incendios forestales en tiempo real y arquitectura Lakehouse distribuida.

1. Â¿De quÃ© trata realmente? (El Negocio)

Imagina que eres el Responsable de Operaciones de TUI en Canarias.

Tienes turistas en Tenerife, Gran Canaria y La Palma.

Problema: Un satÃ©lite detecta un incendio en La Palma. Â¿Debes evacuar el hotel?

Tu SoluciÃ³n: Depende del viento. Si el fuego estÃ¡ a 20km pero el viento sopla hacia el hotel, es peligroso. Si sopla al revÃ©s, no.

Eco-Pulse: Ingesta el dato del fuego, le pregunta a una API de clima "quÃ© tiempo hace justo en esa coordenada", calcula el riesgo y lo guarda para anÃ¡lisis histÃ³rico.

2. Arquitectura de Datos (El "Medallion Architecture")

No vamos a guardar datos a lo loco. Vamos a usar la arquitectura Medallion (Bronce, Plata, Oro) que es el estÃ¡ndar de la industria (Databricks).

Getty Images

Capa Bronze (Raw): Los datos tal cual llegan de la NASA y OpenWeather (sucios, JSONs anidados).

Capa Silver (Cleansed): Datos limpios, deduplicados y con tipos correctos (Fechas como Datetime, Coordenadas como Float).

Capa Gold (Business): Datos agregados. Ejemplo: "Tabla de Riesgo Diario por Isla".

3. Las TecnologÃ­as (Tu Stack)

AquÃ­ estÃ¡ el arsenal que vas a usar. Cada una tiene una funciÃ³n especÃ­fica:

ComponenteTecnologÃ­aFunciÃ³n (El "Por quÃ©")IngestaPython + Apache KafkaPara desacoplar la velocidad de entrada (satÃ©lites) de la velocidad de proceso. Kafka actÃºa de "buffer".ProcesamientoApache Spark (PySpark)El motor. Permite hacer Streaming Joins (unir fuego + viento en movimiento).AlmacenamientoDelta LakeFormato de archivo open source que permite ACID transactions sobre archivos Parquet. Es la magia del Lakehouse.Cloud StorageMinIO (Local) / AWS S3Donde se guardan los archivos fÃ­sicos. MinIO simula S3 en tu PC para que sea gratis.OrquestaciÃ³nDocker ComposePara levantar toda la infraestructura (6 contenedores) con un comando.VisualizaciÃ³nStreamlitPara pintar el mapa con los puntos de fuego y vectores de viento.4. Las APIs y Datos Reales ğŸ“¡

Vas a beber de dos fuentes pÃºblicas increÃ­bles:

A. NASA FIRMS (Fire Information for Resource Management System)

QuÃ© es: Datos casi en tiempo real (NRT) de los satÃ©lites MODIS y VIIRS.

El Dato: Te da Latitud, Longitud, Confidence (0-100% probabilidad de que sea fuego) y Frp (Fire Radiative Power - la intensidad del fuego).

Acceso: Gratis. Te registras y te dan una MAP_KEY.

Formato: CSV o WMS.

B. OpenWeatherMap (API)

QuÃ© es: Datos meteorolÃ³gicos hiper-locales.

El Dato: Te interesa wind_speed (velocidad) y wind_deg (direcciÃ³n en grados).

La LÃ³gica: Cuando recibes un fuego en Lat: 28.0, Lon: -15.5, tu script llama a esta API preguntando: "Â¿QuÃ© viento hace AHORA MISMO en 28.0, -15.5?".

5. El Flujo de Trabajo (Pipeline) ğŸ”„

AsÃ­ es como viaja el dato dentro de tu ordenador:

The Producer (Python):

Consulta a la NASA: "Â¿Nuevos fuegos en Europa?"

Por cada fuego detectado, consulta a OpenWeather: "Â¿Viento en esta zona?"

Empaqueta todo en un JSON: {"lat": 28.1, "lon": -15.4, "wind": 30kmh, "risk": "HIGH"}.

Lo envÃ­a al Topic de Kafka fire-risk-events.

The Stream Processor (Spark):

Lee de Kafka constantemente.

Silver Logic: Convierte el JSON a columnas, filtra fuegos con confidence < 50%.

Escribe en MinIO en formato delta (Ruta: s3a://lakehouse/silver/fire_events).

The Analytics (Spark SQL / Streamlit):

Lee la tabla Delta.

Muestra en el mapa los puntos rojos (fuego) y flechas azules (direcciÃ³n del humo).

6. Â¿Por quÃ© esto es "Nivel Dios"?

Streaming Join: Unir dos fuentes de datos en tiempo real es difÃ­cil. Pocos juniors saben hacerlo.

Delta Lake: Al usar Delta, puedes hacer "Time Travel". En la entrevista podrÃ¡s decir: "Podemos consultar el estado del incendio tal y como estaba ayer a las 18:00, aunque los datos hayan cambiado hoy".

Escalabilidad: Si maÃ±ana en lugar de Europa quieres monitorizar el mundo entero, tu arquitectura aguanta. Solo tienes que aÃ±adir mÃ¡s "Workers" a Spark.

Datos Reales: UsarÃ¡s los satÃ©lites de la NASA (FIRMS) y OpenWeather. Son datos que salvan vidas y son pÃºblicos.
----

1. Â¿Por quÃ© este proyecto es "Gold Standard" para tu CV?
Tu propuesta toca las tres "Vs" del Big Data (Volumen, Velocidad, Variedad) y demuestra competencias clave:

Arquitectura Moderna: El uso de Delta Lake y la arquitectura Medallion es exactamente lo que empresas como Databricks, Microsoft y grandes bancos estÃ¡n implementando ahora mismo. Te alejas del Data Warehouse tradicional y entras en el mundo del Lakehouse.

Desacoplamiento: Entender que Kafka actÃºa como buffer para que el sistema no colapse si la NASA envÃ­a millones de datos de golpe es un concepto de System Design fundamental.

Problema Real: La narrativa de "TUI en Canarias" es brillante. Consejo de oro: En las entrevistas, empieza SIEMPRE por el problema de negocio (salvar vidas/turismo), no por el cÃ³digo.


Getty Images
2. AnÃ¡lisis TÃ©cnico y Ajustes de "Nivel Experto"
Aunque el plan es excelente, quiero afinar un par de tuercas para que cuando te entreviste un Senior Staff Engineer, no te pille en renuncio.

A. La Trampa del "Streaming Join" (Importante)
En tu descripciÃ³n dices:

Producer: Consulta NASA -> Consulta Weather -> Empaqueta JSON -> EnvÃ­a a Kafka.

Spark: Lee Kafka -> Procesa.

Ojo con la terminologÃ­a: Tal como lo describes en el paso 1, NO estÃ¡s haciendo un Streaming Join en Spark. EstÃ¡s haciendo Enriquecimiento en la Ingesta (Ingestion Enrichment). El dato ya llega unido a Spark.

OpciÃ³n A (La que describes - MÃ¡s fÃ¡cil y robusta): Es vÃ¡lida. Reduces complejidad en Spark, pero aumentas latencia en el productor (si la API del clima falla, pierdes el dato del fuego o se bloquea el script).

OpciÃ³n B (El verdadero "Nivel Dios" - Streaming Join):

Producer 1: EnvÃ­a datos de Fuego al Topic fire-events.

Producer 2: EnvÃ­a datos de Clima al Topic weather-events.

Spark: Lee ambos topics y los une en tiempo real basÃ¡ndose en coordenadas geogrÃ¡ficas (geo-spatial join) o tiempo.

Veredicto: Si quieres vender "Streaming Joins" en la entrevista, ve por la OpciÃ³n B. Si quieres vender "Robustez", quÃ©date con la A, pero llÃ¡malo "Enriquecimiento pre-ingesta".

B. El EslabÃ³n Perdido: OrquestaciÃ³n y Calidad
Tu stack es bueno, pero le faltan dos piezas para ser un entorno productivo real:

Calidad del Dato (Data Quality):

Â¿QuÃ© pasa si la NASA envÃ­a una latitud 999? Tu pipeline explotarÃ¡ o ensuciarÃ¡ la capa Silver.

AcciÃ³n: Implementa Great Expectations (librerÃ­a Python) dentro de tu pipeline de Spark o como paso intermedio para validar que los datos cumplen las reglas antes de pasar a Silver.

OrquestaciÃ³n (El que manda):

Mencionas Docker Compose (infraestructura), pero Â¿quiÃ©n dispara los scripts?

Para un proceso de Streaming continuo, Spark corre siempre. Pero para mantenimientos o procesos batch (ej: compactar archivos Delta pequeÃ±os en uno grande - VACUUM), necesitas un orquestador.

AcciÃ³n: Considera aÃ±adir Airflow o Mage.ai (mÃ¡s moderno) para orquestar la limpieza del Lakehouse.

3. Hoja de Ruta para Construirlo (Plan de Mentor)
No intentes hacerlo todo a la vez. Sigue este orden para no frustrarte:

Fase 1: El MVP (Minimum Viable Pipeline)

Script Python simple que lee NASA API y guarda en un CSV local.

Levantar Kafka y Zookeeper con Docker.

Hacer que el script envÃ­e al topic de Kafka.

Fase 2: El Motor Spark

Levantar Spark y MinIO con Docker.

Script PySpark que lee de Kafka y escribe en consola (console sink).

Cambiar la escritura de consola a MinIO (formato Delta).

Fase 3: La LÃ³gica de Negocio (Medallion)

Implementar la separaciÃ³n Bronze (Raw) -> Silver (Clean) -> Gold (Aggregated).

AquÃ­ es donde aplicas la lÃ³gica de "Risk = High/Low".

Fase 4: La Capa Visual

Conectar Streamlit a la tabla Delta (Gold) y pintar el mapa.

4. SimulaciÃ³n de Entrevista: Â¿CÃ³mo defenderlo?
Cuando te pregunten por este proyecto, usa este guion:

Entrevistador: "CuÃ©ntame sobre el proyecto Eco-Pulse."

TÃº: "Lo construÃ­ porque querÃ­a resolver un problema de latencia en la toma de decisiones de seguridad turÃ­stica.

El Reto: Detectar incendios y correlacionarlos con el viento en tiempo real para evaluar riesgos de evacuaciÃ³n.

La Arquitectura: ElegÃ­ una arquitectura Lakehouse sobre Delta Lake para garantizar transacciones ACID. UtilicÃ© Kafka para desacoplar la ingesta de la NASA del procesamiento, lo que me permite escalar los productores sin tocar el cluster de Spark.

La decisiÃ³n tÃ©cnica mÃ¡s difÃ­cil: Fue elegir dÃ³nde hacer el cruce de datos. DecidÃ­ hacerlo [en la ingesta / en Spark] porque [razÃ³n de latencia / razÃ³n de escalabilidad].

El resultado: Un dashboard en Streamlit que actualiza el riesgo cada X segundos, con capacidad de 'Time Travel' para auditorÃ­as forenses gracias a Delta."


Tu intuiciÃ³n es correcta, pero vamos a precisar un detalle tÃ©cnico importante: Spark NO habla con los Producers.

El flujo es asÃ­:

NASA Producer: "Â¡Tengo un incendio!" -> Lo lanza al buzÃ³n de Kafka (topic: fire-events).

Weather Producer: "Â¡Tengo viento!" -> Lo lanza al buzÃ³n de Kafka (topic: weather-events).

(AquÃ­ los datos esperan en el buzÃ³n hasta que alguien los recoja).

Spark (Processor): Va al buzÃ³n de Kafka constantemente, recoge las cartas nuevas, las limpia (les pone tipos de datos correctos, timestamps, etc.) y las archiva ordenadas en MinIO (Tu Data Lake).

AsÃ­ que sÃ­: Spark recoge de Kafka y guarda en MinIO.

3. El Orden de Encendido (El Protocolo de Arranque) ğŸš¦
En un sistema desacoplado (gracias a Kafka), el orden no es estricto (no explota si lo haces mal), pero el orden lÃ³gico profesional es este:

PASO 1: La Infraestructura (El Suelo)

Terminal 1: docker-compose up -d

Sin esto, no hay buzÃ³n (Kafka) ni archivo (MinIO).

PASO 2: La Ingesta (Los Proveedores)

Terminal 2: python src/ingestion/nasa_producer.py

Terminal 3: python src/ingestion/weather_producer.py

Estos empiezan a llenar Kafka de datos. Si Spark estÃ¡ apagado, no pasa nada, Kafka guarda los mensajes (por defecto hasta 7 dÃ­as).

silver/: AquÃ­ viven tus datos. Si entras, verÃ¡s archivos .parquet (y carpetas _delta_log). Son tus datos de incendios y clima guardados en un formato comprimido y optimizado para Big Data.

checkpoints/: Esta es la "memoria" de Spark. Como es un proceso continuo, Spark apunta aquÃ­ quÃ© mensajes ya ha leÃ­do. Si se va la luz y reinicias el script, Spark mirarÃ¡ aquÃ­ y dirÃ¡: "Me quedÃ© en el mensaje 502", y seguirÃ¡ desde ahÃ­ sin duplicar datos. Esto es la tolerancia a fallos.
